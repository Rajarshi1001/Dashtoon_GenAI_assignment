{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import vgg19\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_img(image_path):\n",
    "    max_dim = 512\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "    shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
    "    long_dim = max(shape)\n",
    "    scale = max_dim / long_dim\n",
    "\n",
    "    new_shape = tf.cast(shape * scale, tf.int32)\n",
    "    img = tf.image.resize(img, new_shape)\n",
    "    img = img[tf.newaxis, :]\n",
    "    return img\n",
    "\n",
    "# Replace these paths with your actual image paths\n",
    "content_path = 'image1.png'\n",
    "style_path = 'image2.png'\n",
    "\n",
    "content_image = load_and_process_img(content_path)\n",
    "style_image = load_and_process_img(style_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "47104000/80134624 [================>.............] - ETA: 3s"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    vgg = vgg19.VGG19(include_top=False, weights='imagenet')\n",
    "    vgg.trainable = False\n",
    "    style_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
    "    content_layers = ['block5_conv2']\n",
    "    model_outputs = [vgg.get_layer(name).output for name in style_layers + content_layers]\n",
    "    return Model([vgg.input], model_outputs)\n",
    "\n",
    "model = get_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_loss(base_content, target):\n",
    "    return tf.reduce_mean(tf.square(base_content - target))\n",
    "\n",
    "def gram_matrix(input_tensor):\n",
    "    channels = int(input_tensor.shape[-1])\n",
    "    a = tf.reshape(input_tensor, [-1, channels])\n",
    "    n = tf.shape(a)[0]\n",
    "    gram = tf.matmul(a, a, transpose_a=True)\n",
    "    return gram / tf.cast(n, tf.float32)\n",
    "\n",
    "def get_style_loss(base_style, gram_target):\n",
    "    gram_style = gram_matrix(base_style)\n",
    "    return tf.reduce_mean(tf.square(gram_style - gram_target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_representations(model, content_path, style_path):\n",
    "    content_image = load_and_process_img(content_path)\n",
    "    style_image = load_and_process_img(style_path)\n",
    "    style_outputs = model(style_image)\n",
    "    content_outputs = model(content_image)\n",
    "    style_features = [style_layer[0] for style_layer in style_outputs[:5]]\n",
    "    content_features = [content_layer[0] for content_layer in content_outputs[5:]]\n",
    "    return style_features, content_features\n",
    "\n",
    "def compute_loss_and_grads(model, loss_weights, init_image, gram_style_features, content_features):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = model(init_image)\n",
    "        style_output_features = outputs[:5]\n",
    "        content_output_features = outputs[5:]\n",
    "\n",
    "        style_score = 0\n",
    "        content_score = 0\n",
    "\n",
    "        weight_per_style_layer = 1.0 / float(len(style_layers))\n",
    "        for target_style, comb_style in zip(gram_style_features, style_output_features):\n",
    "            style_score += weight_per_style_layer * get_style_loss(comb_style[0], target_style)\n",
    "\n",
    "        weight_per_content_layer = 1.0 / float(len(content_layers))\n",
    "        for target_content, comb_content in zip(content_features, content_output_features):\n",
    "            content_score += weight_per_content_layer * get_content_loss(comb_content[0], target_content)\n",
    "\n",
    "        style_score *= loss_weights[0]\n",
    "        content_score *= loss_weights[1]\n",
    "\n",
    "        loss = style_score + content_score \n",
    "    return loss, tape.gradient(loss, init_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image):\n",
    "    if len(image.shape) > 3:\n",
    "        image = tf.squeeze(image, axis=0)\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
